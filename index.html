<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Blendshape + 音频控制 + 摄像头背景</title>
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <style>
      body { margin: 0; overflow: hidden; }
      .btn-container {
        position: absolute;
        top: 10px;
        left: 10px;
        z-index: 2;
      }
      button {
        margin: 4px;
        padding: 6px 12px;
        font-size: 14px;
      }
    </style>
  </head>
  <body>
    <!-- 音频选择按钮 -->
    <div class="btn-container">
      <button onclick="playAudio('AnotherDayOfSun.MP3')">Audio 1</button>
      <button onclick="playAudio('AnotherDayOfSun2.MP3')">Audio 2</button>
      <button onclick="playAudio('AnotherDayOfSun3.MP3')">Audio 3</button>
    </div>

    <!-- 摄像头视频元素 -->
    <video id="cam" autoplay muted playsinline style="display: none;"></video>

    <!-- A-Frame 场景 -->
    <a-scene>
      <!-- 摄像头背景 -->
      <a-video 
        src="#cam" 
        position="0 1.5 -4" 
        width="8" 
        height="4.5"
      ></a-video>

      <!-- 摄像头位置 -->
      <a-entity id="camera" camera look-controls position="0 1.6 0"></a-entity>

      <!-- 加载 glb 模型（包含 blendshape） -->
      <a-entity id="blendshape-model" gltf-model="Cube_Blendshape_test.glb" position="0 1 -2" scale="1 1 1"></a-entity>
    </a-scene>

    <script>
      // 摄像头背景
      const video = document.getElementById('cam');
      navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        video.srcObject = stream;
      }).catch(err => {
        alert('摄像头启动失败: ' + err);
      });

      let audioContext, audioSource, analyser, dataArray, currentAudio;
      let modelMesh; // 将来指向包含 morphTargetInfluences 的网格

      const modelEntity = document.querySelector('#blendshape-model');

      // 当模型加载完成后，获取其 mesh 对象
      modelEntity.addEventListener('model-loaded', () => {
        const mesh = modelEntity.getObject3D('mesh');
        mesh.traverse(node => {
          if (node.isMesh && node.morphTargetInfluences) {
            modelMesh = node;
          }
        });
      });

      function playAudio(filename) {
        if (currentAudio) {
          currentAudio.pause();
          currentAudio = null;
        }
        if (audioContext) {
          audioContext.close();
        }

        currentAudio = new Audio(filename);
        currentAudio.loop = true;
        currentAudio.autoplay = true;

        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        audioSource = audioContext.createMediaElementSource(currentAudio);
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 64;
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        audioSource.connect(analyser);
        analyser.connect(audioContext.destination);

        currentAudio.play();
        audioContext.resume();
        animate();
      }

      function animate() {
        if (!analyser) return;
        requestAnimationFrame(animate);

        analyser.getByteFrequencyData(dataArray);
        const avgFreq = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

        const influence = Math.min(avgFreq / 100, 1); // 限制在 0~1 之间

        if (modelMesh && modelMesh.morphTargetInfluences) {
          modelMesh.morphTargetInfluences[0] = influence; // 控制第一个 blendshape
        }
      }
    </script>
  </body>
</html>
